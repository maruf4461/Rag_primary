{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Python Environment (Using Conda)"
      ],
      "metadata": {
        "id": "dpzWEAu3ktoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 1: Check GPU and Mount Drive"
      ],
      "metadata": {
        "id": "erQ3jvA8mdjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 01_Environment_Setup.ipynb\n",
        "\n",
        "# ==========================================\n",
        "# CELL 1: Check GPU and Mount Drive\n",
        "# ==========================================\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"üîç Checking GPU availability...\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name()\n",
        "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
        "    print(f\"üìä GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ùå No GPU available. Please enable GPU in Runtime > Change runtime type\")\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"\\nüìÇ Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project directory\n",
        "project_dir = '/content/drive/MyDrive/RAG_Research'\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/notebooks', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/data/raw', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/data/processed', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/data/embeddings', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/models', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/results', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/src', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/configs', exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Project structure created!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVQsfhiemRWH",
        "outputId": "3b367d48-99ad-48c3-8f97-dd38b50fd410"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Checking GPU availability...\n",
            "‚ùå No GPU available. Please enable GPU in Runtime > Change runtime type\n",
            "\n",
            "üìÇ Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "‚úÖ Project structure created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 2: Install Dependencies"
      ],
      "metadata": {
        "id": "mv8aLbAKmmAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install core packages\n",
        "!pip install -q transformers>=4.30.0\n",
        "!pip install -q sentence-transformers>=2.2.0\n",
        "!pip install -q datasets>=2.12.0\n",
        "!pip install -q accelerate>=0.20.0\n",
        "!pip install -q chromadb>=0.4.0\n",
        "!pip install -q faiss-cpu>=1.7.4  # Changed from faiss-gpu\n",
        "!pip install -q rouge-score>=0.1.2\n",
        "!pip install -q bert-score>=0.3.13\n",
        "!pip install -q wandb>=0.15.0\n",
        "!pip install -q pandas numpy scikit-learn tqdm\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fquo1uwpaiL",
        "outputId": "fc4bc1a3-b6a5-4b82-be21-1f2581c73cf8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All dependencies installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 3: Create Utility Functions"
      ],
      "metadata": {
        "id": "DZV58GHAmvjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/RAG_Research/src')\n",
        "\n",
        "# Save this as a file for reuse\n",
        "utils_code = '''\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import torch\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "class ColabUtils:\n",
        "    \"\"\"Utility functions optimized for Google Colab\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def save_to_drive(data, filepath):\n",
        "        \"\"\"Save data to Google Drive with proper error handling\"\"\"\n",
        "        try:\n",
        "            drive_path = f\"/content/drive/MyDrive/RAG_Research/{filepath}\"\n",
        "            os.makedirs(os.path.dirname(drive_path), exist_ok=True)\n",
        "\n",
        "            if filepath.endswith('.json'):\n",
        "                with open(drive_path, 'w') as f:\n",
        "                    json.dump(data, f, indent=2)\n",
        "            elif filepath.endswith('.pkl'):\n",
        "                with open(drive_path, 'wb') as f:\n",
        "                    pickle.dump(data, f)\n",
        "            elif filepath.endswith('.csv'):\n",
        "                data.to_csv(drive_path, index=False)\n",
        "\n",
        "            print(f\"‚úÖ Saved to: {drive_path}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error saving {filepath}: {e}\")\n",
        "            return False\n",
        "\n",
        "    @staticmethod\n",
        "    def load_from_drive(filepath):\n",
        "        \"\"\"Load data from Google Drive\"\"\"\n",
        "        try:\n",
        "            drive_path = f\"/content/drive/MyDrive/RAG_Research/{filepath}\"\n",
        "\n",
        "            if filepath.endswith('.json'):\n",
        "                with open(drive_path, 'r') as f:\n",
        "                    return json.load(f)\n",
        "            elif filepath.endswith('.pkl'):\n",
        "                with open(drive_path, 'rb') as f:\n",
        "                    return pickle.load(f)\n",
        "            elif filepath.endswith('.csv'):\n",
        "                return pd.read_csv(drive_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading {filepath}: {e}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def clear_gpu_memory():\n",
        "        \"\"\"Clear GPU memory to prevent OOM errors\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            print(\"üßπ GPU memory cleared\")\n",
        "\n",
        "    @staticmethod\n",
        "    def check_disk_space():\n",
        "        \"\"\"Check available disk space\"\"\"\n",
        "        statvfs = os.statvfs('/content')\n",
        "        free_space = statvfs.f_frsize * statvfs.f_bavail / (1024**3)\n",
        "        print(f\"üíæ Available disk space: {free_space:.2f} GB\")\n",
        "        return free_space\n",
        "\n",
        "    @staticmethod\n",
        "    def get_runtime_info():\n",
        "        \"\"\"Get current runtime information\"\"\"\n",
        "        import psutil\n",
        "\n",
        "        # GPU info\n",
        "        if torch.cuda.is_available():\n",
        "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "            gpu_used = torch.cuda.memory_allocated() / 1e9\n",
        "            gpu_free = gpu_memory - gpu_used\n",
        "        else:\n",
        "            gpu_memory = gpu_used = gpu_free = 0\n",
        "\n",
        "        # RAM info\n",
        "        ram = psutil.virtual_memory()\n",
        "        ram_total = ram.total / 1e9\n",
        "        ram_used = ram.used / 1e9\n",
        "        ram_free = ram.available / 1e9\n",
        "\n",
        "        print(f\"üñ•Ô∏è  Runtime Info:\")\n",
        "        print(f\"   GPU Memory: {gpu_used:.1f}/{gpu_memory:.1f} GB\")\n",
        "        print(f\"   RAM: {ram_used:.1f}/{ram_total:.1f} GB\")\n",
        "        print(f\"   Disk: {ColabUtils.check_disk_space():.1f} GB free\")\n",
        "\n",
        "        return {\n",
        "            'gpu_total': gpu_memory,\n",
        "            'gpu_used': gpu_used,\n",
        "            'ram_total': ram_total,\n",
        "            'ram_used': ram_used\n",
        "        }\n",
        "'''\n",
        "\n",
        "# Save utils to file\n",
        "with open('/content/drive/MyDrive/RAG_Research/src/colab_utils.py', 'w') as f:\n",
        "    f.write(utils_code)\n",
        "\n",
        "# Import the utils\n",
        "from colab_utils import ColabUtils\n",
        "utils = ColabUtils()\n",
        "\n",
        "print(\"‚úÖ Utility functions created and loaded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byabrbb2mdH5",
        "outputId": "f113eaf7-b0cd-4521-ce9c-37f06d46baf9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Utility functions created and loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CELL 4: Test Environment"
      ],
      "metadata": {
        "id": "M0vZ7r5znJEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "# Test the setup\n",
        "utils.get_runtime_info()\n",
        "\n",
        "# Test saving/loading\n",
        "test_data = {\"test\": \"data\", \"timestamp\": str(datetime.now())}\n",
        "utils.save_to_drive(test_data, \"results/test_save.json\")\n",
        "loaded_data = utils.load_from_drive(\"results/test_save.json\")\n",
        "print(f\"‚úÖ Save/Load test: {loaded_data}\")\n",
        "\n",
        "print(\"\\nüéâ Environment setup complete! You can now proceed to data preparation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpIdGJnsmdK4",
        "outputId": "7f773bcd-c0f1-48de-eff6-f109066e0822"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñ•Ô∏è  Runtime Info:\n",
            "   GPU Memory: 0.0/0.0 GB\n",
            "   RAM: 1.3/13.6 GB\n",
            "üíæ Available disk space: 65.80 GB\n",
            "   Disk: 65.8 GB free\n",
            "‚úÖ Saved to: /content/drive/MyDrive/RAG_Research/results/test_save.json\n",
            "‚úÖ Save/Load test: {'test': 'data', 'timestamp': '2025-06-23 11:59:49.708881'}\n",
            "\n",
            "üéâ Environment setup complete! You can now proceed to data preparation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HG8pbx26mdQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WahlBfVImdTF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}